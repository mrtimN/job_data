{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "30d0f432-9e0d-4940-8b96-ad8b5d206202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install curl_cffi\n",
    "import pandas as pd\n",
    "import plotly as pl\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from curl_cffi import requests as cureq\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "url = 'data/combined_job_offers.csv'\n",
    "url2 = 'data/combined_job_offers3.csv'\n",
    "url_scraped = 'data/scraped_data.csv'\n",
    "\n",
    "# reading the 2 base datasets\n",
    "df1 = pd.read_csv(url)\n",
    "df2 = pd.read_csv(url2)\n",
    "\n",
    "df3 = pd.concat([df1,df2],axis=0)\n",
    "\n",
    "#reading the dataset, scraped from stepstone\n",
    "df_scraped = pd.read_csv(url_scraped)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4f9bd5c2-b2eb-4d2b-b44c-c79a5042f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the base dataset\n",
    "# 1 drop columns df3\n",
    "df3.drop(columns =['repost_date', 'email', 'job_desc'], inplace=True)\n",
    "\n",
    "# 2 Renaming 'link'\n",
    "df3.rename(columns={'link': 'source'}, inplace=True)\n",
    "\n",
    "# 3 replace all links with LinkedIn\n",
    "# apply lambda for each cell replace all string\n",
    "df3['source'] = df3['source'].apply(lambda x: 'LinkedIn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a4303ef9-16c0-4162-a575-437d1317dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates from scraped dataset\n",
    "df_scraped.drop_duplicates(subset=['job_title', 'company_name', 'post_date'], keep='last', inplace=True)\n",
    "\n",
    "# combine scraped dataset with base dataset\n",
    "df_combined = pd.concat([df3,df_scraped],axis=0)\n",
    "\n",
    "# apply wrangling the job_levels\n",
    "df_combined['job_level'] = df_combined.apply(replace_nan_with_job_level, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9f838e0c-48d9-4b2a-ac18-a56804331d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stepstone(job_title, page, language, worktime, sector):\n",
    "    url = f'https://www.stepstone.de/jobs/{worktime}/{job_title}/in-berlin?radius=30&whereType=autosuggest&page={page}action=facet_selected%3bworktypes%3b80001&fdl={language}&se={sector}&wci=419239&sort=1&action=sort_relevance'\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    print(url)\n",
    "    print('---------------------------------')\n",
    "    \n",
    "    response = cureq.get(url, impersonate='chrome')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def enrich_dataset(job_title, page, language, worktime, sector, dataframe):\n",
    "    df_base = dataframe\n",
    "    df_enrich = dataframe.drop(dataframe.index)\n",
    "    \n",
    "    # scrape the initial result via scrape function\n",
    "    scrape_result = scrape_stepstone(job_title, page, language, worktime, sector)\n",
    "    \n",
    "    # get all job listings\n",
    "    job_offer_list = scrape_result.find_all(['article'], attrs={'class': 'res-1p8f8en'})\n",
    "\n",
    "    # set language, job_type, sector, source, search term according to search parameters\n",
    "    job_type_list = []\n",
    "    language_list = []\n",
    "    sector_list = []\n",
    "    source_list = []\n",
    "    search_term_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        job_type_list.append((lambda worktime: 'Full-time' if worktime == 'vollzeit' else 'Part-time' if worktime == 'teilzeit' else 'Unknown')(worktime))\n",
    "        language_list.append(language)\n",
    "        sector_list.append((lambda sector: 'IT Services and IT Consulting' if sector == '21000' else 'Business Consulting and Services' if sector == '23000' else 'Retail' if sector == '15000' else 'Finance' if sector == '19001' or sector == '19002' else 'Unknown')(sector))\n",
    "        source_list.append('stepstone')\n",
    "        search_term_list.append(job_title.replace('-', ' '))\n",
    "        \n",
    "    # scrape job titles\n",
    "    job_title_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        job_title_list.append(job_offer.find(['div'], attrs={'class': 'res-nehv70'}).get_text())\n",
    "    \n",
    "    # scrape company names\n",
    "    company_name_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        company_name_list.append(job_offer.find(['span'], attrs={'class': 'res-btchsq'}).get_text())\n",
    "    \n",
    "    # scrape post date\n",
    "    post_date_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        post_date_list.append(handle_date(job_offer.find(['time']).get_text()))\n",
    "    \n",
    "    # scrape salary - only possible with login\n",
    "    #salary_list = []\n",
    "    #for job_offer in job_offer_list:\n",
    "        #job_offer.find_all(['div'], attrs={'class': 'res-lgmafx'})[0]\n",
    "        #salary_list.append(job_offer.find(['span'], attrs={'class': 'res-1fad2gj'}).get_text())\n",
    "\n",
    "    # scrape and wrangle remote \n",
    "    job_remote_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        result = job_offer.find_all(['div'], attrs={'class': 'res-lgmafx'})\n",
    "        remote = result[0].find(['span'], attrs={'class': 'res-1qh7elo'})\n",
    "        if not remote:\n",
    "            job_remote_list.append('On-site')\n",
    "        else:\n",
    "            remote_text = remote.find(['span'], attrs={'class': 'res-btchsq'}).get_text()\n",
    "            if remote_text == 'Teilweise Home-Office':\n",
    "                job_remote_list.append('Hybrid')\n",
    "            elif remote_text == 'Nur Home-Office':\n",
    "                job_remote_list.append('Remote')\n",
    "            else:\n",
    "                job_remote_list.append('On-site')\n",
    "    \n",
    "    # fill the dataframe with the list values\n",
    "    df_enrich['job_title'] = job_title_list\n",
    "    df_enrich['company_name'] = company_name_list\n",
    "    df_enrich['post_date'] = post_date_list\n",
    "    #df_enrich[''] = number_of_employees\n",
    "    #df_enrich[''] = num_applicants\n",
    "    df_enrich['job_type'] = job_type_list\n",
    "    df_enrich['job_remote'] = job_remote_list\n",
    "    df_enrich['language'] = language_list    \n",
    "    #df_enrich[''] = salary_list\n",
    "    df_enrich['sector'] = sector_list\n",
    "    df_enrich['source'] = source_list\n",
    "    df_enrich['search_term'] = search_term_list\n",
    "\n",
    "    # combine base dataframe with the enriching data\n",
    "    df_combined = pd.concat([df_base, df_enrich],axis=0)\n",
    "    return df_combined\n",
    "\n",
    "# execute the scrape function in a nested loop to scrape a lot of data\n",
    "def scrape_a_lot(df_base):\n",
    "    # define the search parameters for the iterative scraping\n",
    "    search_terms = ['data analyst', 'data engineer', 'data scientist']\n",
    "    languages = ['en', 'de']\n",
    "    worktimes = ['vollzeit', 'teilzeit']\n",
    "    #21000 for 'it & internet', 23000 for 'bwl/business' 15000 for 'retail', 19001 for 'bank', 19002 for 'finance'  \n",
    "    sectors = ['21000', '23000', '15000', '19002']\n",
    "    df_temp = df_base.drop(df_base.index)\n",
    "    \n",
    "    # !!!BE CAREFUL - DO NOT UNCOMMENT AND EXECUTE!!!\n",
    "    # this will cause a lot of requests in short time and might result in an IP ban\n",
    "    #for language in languages:\n",
    "    #    for worktime in worktimes:\n",
    "    #        for search in search_terms:\n",
    "    #            for sector in sectors:\n",
    "    #                for i in range(1,3):\n",
    "    #                    df_temp = enrich_dataset(search, str(i), language, worktime, sector, df_base)\n",
    "    return df_temp\n",
    "\n",
    "# function to handle date format like \"1 week ago\" and convert it to datetime format\n",
    "def handle_date(stepstone_post_date):\n",
    "    sliced = stepstone_post_date.split(' ', 2)\n",
    "    date_number = int(sliced[1])\n",
    "    time_format = sliced[2]\n",
    "    date = datetime.now()\n",
    "    \n",
    "    match time_format:\n",
    "        case 'Stunden' | 'Stunde':\n",
    "            date = date - timedelta(hours=date_number)\n",
    "        case 'Tagen' | 'Tag':\n",
    "            date = date - timedelta(days=date_number)\n",
    "        case 'Wochen' | 'Woche':\n",
    "            date = date - timedelta(weeks=date_number)\n",
    "        case 'Monate' | 'Monat':\n",
    "            date = date - timedelta(months=date_number)\n",
    "        case _:\n",
    "           date = date\n",
    "    return date.strftime('%d-%m-%Y')\n",
    "\n",
    "# 3 job_type wrangling: extract_job_type for NaN with keywords and 'Unknown'\n",
    "def replace_nan_with_job_level(row):\n",
    "    keywords = ['Senior', 'Mid-Senior level', 'Associate', 'Entry', 'Entry level','Werkstudent', 'Junior', 'Consultant', 'Developer', 'Mid', 'Intern', 'Lead', 'Manager', 'Internship', 'Entry level','Director', 'Mid-Senior']\n",
    "    \n",
    "    if pd.isna(row['job_level']):\n",
    "        for keyword in keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', row['job_title'], re.IGNORECASE):\n",
    "                return keyword\n",
    "        return 'Unknown' \n",
    "    return row['job_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b18a16-3dad-4ff4-9fba-7e5068eb7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fed25e-acf7-4152-842c-ab3a22f1a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_sectors = test['sector'].value_counts().head(10)\n",
    "top_5_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d486ec-bf61-42ab-86ba-db7dc6337552",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['job_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13177034-b66e-4b06-93eb-9066d86a8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_sectors2 = test['job_level'].unique()\n",
    "top_5_sectors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce175b-6398-4674-8cd3-dd2d5501ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby([\"job_level\", \"sector\"])[\"job_type\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320925c3-47e5-4276-8e13-5fea5e4b96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_level_range = test[\n",
    "    (test[''.isin([''])) &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2f5c2-66a9-4c5f-b1ca-02a0b4df74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# job categories and experience\n",
    "job_experience = {\n",
    "    'Entry level': 0-3,\n",
    "    'Junior': 1,  # Averaging between 0-2 years\n",
    "    'Associate': 2,  # Averaging between 1-3 years\n",
    "    'Mid-Senior level': 4,  # Averaging between 3-5 years\n",
    "    'Senior': 7.5,  # Averaging between 5-10 years\n",
    "    'Lead': 7.5,  # Averaging between 5-10 years\n",
    "    'Manager': 10,  # At the start of the 5-10+ range\n",
    "    'Executive': 10,\n",
    "    'Director': 10,\n",
    "    'Consultant': 10,\n",
    "    'Unknown': float('nan')  # For visualization purposes, use NaN\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(list(job_experience.items()), columns=['Sector', 'Years of Experience'])\n",
    "\n",
    "# Exclude 'Unknown' for some visualizations if they include NaN\n",
    "df_filtered = df.dropna()\n",
    "\n",
    "# Plotting with Seaborn\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.barplot(x='Sector', y='Years of Experience', data=df_filtered, palette='viridis')\n",
    "\n",
    "plt.title('Breakdown of Job Categories by Years of Experience')\n",
    "plt.xlabel('Job Sector')\n",
    "plt.ylabel('Years of Experience')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c59ea-b5bf-4b7a-99a7-c9109241085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb51df5-3556-40a7-a199-db529d89b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_data = test.groupby([\"job_level\", \"sector\"])[\"job_type\"].count().reset_index()\n",
    "\n",
    "# Rename the count column for clarity\n",
    "grouped_data = grouped_data.rename(columns={\"job_type\": \"type_count\"})\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=grouped_data, x=\"job_level\", y=\"type_count\", hue=\"sector\", dodge=True)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Job Type Count by Job Level and Sector\")\n",
    "plt.xlabel(\"Job Level\")\n",
    "plt.ylabel(\"Count of Job Types\")\n",
    "plt.legend(title=\"Sector\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce025a-3ad9-4962-91e4-b1d113738847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define job sectors and hypothetical counts of data analysts\n",
    "job_sectors = {\n",
    "    'Information Technology & Services': 700,\n",
    "    'Financial Services': 500,\n",
    "    'Engineering Services': 400,\n",
    "    'Software Development': 650,\n",
    "    'Retail': 300,\n",
    "    'Marketing Services': 350,\n",
    "    'Telecommunications': 450,\n",
    "    'Biotechnology': 200,\n",
    "    'Education': 250,\n",
    "    'Healthcare': 300\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_sectors = pd.DataFrame(list(job_sectors.items()), columns=['Sector', 'Data Analysts'])\n",
    "\n",
    "# Sort the DataFrame for a better visualization\n",
    "df_sectors = df_sectors.sort_values(by='Data Analysts', ascending=False)\n",
    "\n",
    "# Plot using Seaborn, flipping x and y\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(y='Data Analysts', x='Sector', data=df_sectors, palette='coolwarm')\n",
    "\n",
    "plt.title('Top 10 Job Sectors for Data Analysts in Germany')\n",
    "plt.ylabel('Number of Data Analysts')\n",
    "plt.xlabel('Job Sector')\n",
    "plt.xticks(rotation=45)  # Rotate x labels for better visibility\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
