{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d0f432-9e0d-4940-8b96-ad8b5d206202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install curl_cffi\n",
    "import pandas as pd\n",
    "import plotly as pl\n",
    "from bs4 import BeautifulSoup\n",
    "from curl_cffi import requests as cureq\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "url = 'data/combined_job_offers.csv'\n",
    "url2 = 'data/combined_job_offers3.csv'\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df2 = pd.read_csv(url2)\n",
    "\n",
    "df3 = pd.concat([df1,df2],axis=0)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9bd5c2-b2eb-4d2b-b44c-c79a5042f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "# 1 drop columns df3\n",
    "df3.drop(columns =['repost_date', 'email', 'job_desc'], inplace=True)\n",
    "# 2 Renaming 'link'\n",
    "df3.rename(columns={'link': 'source'}, inplace=True)\n",
    "# 3 replace all links with LinkedIn\n",
    "# apply lambda for each cell replace all string\n",
    "df3['source'] = df3['source'].apply(lambda x: 'LinkedIn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f838e0c-48d9-4b2a-ac18-a56804331d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stepstone(job_title, page, language, worktime, sector):\n",
    "\n",
    "    #lang_filter = f'&action=facet_selected%3bdetectedLanguages%3bde&fdl={language}' # must be 'de' or 'en'\n",
    "    #worktime_filter = f'&action=facet_selected%3bworktypes%3b8000{worktime}' # must be '1' for fulltime or '2' for parttime\n",
    "    #sector_filter = f'&action=facet_selected%3bsectors%3b21000&se={sector}' # 21000 for 'it & internet', 23000 for 'bwl/business' 15000 for 'retail', 19001 for 'bank', 19002 for 'finance'  \n",
    "\n",
    "    # compare number of existing pages to user entries\n",
    "    #url = f'https://www.stepstone.de/jobs/{job_title}/in-berlin?radius=10&page={page}{lang_filter}{worktime_filter}{worktime_filter}' # job_title must be tile with '-' separator\n",
    "    \n",
    "    url = f'https://www.stepstone.de/jobs/{worktime}/{job_title}/in-berlin?radius=30&whereType=autosuggest&page={page}action=facet_selected%3bworktypes%3b80001&fdl={language}&se={sector}&wci=419239&sort=1&action=sort_relevance'\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    print(url)\n",
    "    print('---------------------------------')\n",
    "    \n",
    "    response = cureq.get(url, impersonate='chrome')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def enrich_dataset(job_title, page, language, worktime, sector, dataframe):\n",
    "\n",
    "    df_base = dataframe\n",
    "    df_enrich = dataframe.drop(dataframe.index)\n",
    "    \n",
    "    # scrape the initial result via scrape function\n",
    "    scrape_result = scrape_stepstone(job_title, page, language, worktime, sector)\n",
    "    \n",
    "    # get all job listings\n",
    "    job_offer_list = scrape_result.find_all(['article'], attrs={'class': 'res-1p8f8en'})\n",
    "\n",
    "    # set language, job_type, sector, source, search term according to search parameters\n",
    "    job_type_list = []\n",
    "    language_list = []\n",
    "    sector_list = []\n",
    "    source_list = []\n",
    "    search_term_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        job_type_list.append((lambda worktime: 'Full-time' if worktime == 'vollzeit' else 'Part-time' if worktime == 'teilzeit' else 'Unknown')(worktime))\n",
    "        language_list.append(language)\n",
    "        sector_list.append((lambda sector: 'IT Services and IT Consulting' if sector == '21000' else 'Business Consulting and Services' if sector == '23000' else 'Retail' if sector == '15000' else 'Finance' if sector == '19001' or sector == '19002' else 'Unknown')(sector))\n",
    "        source_list.append('stepstone')\n",
    "        search_term_list.append(job_title.replace('-', ' '))\n",
    "        \n",
    "    # scrape job titles\n",
    "    job_title_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        job_title_list.append(job_offer.find(['div'], attrs={'class': 'res-nehv70'}).get_text())\n",
    "    \n",
    "    # scrape company names\n",
    "    company_name_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        company_name_list.append(job_offer.find(['span'], attrs={'class': 'res-btchsq'}).get_text())\n",
    "    \n",
    "    # scrape post date\n",
    "    post_date_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        post_date_list.append(handle_date(job_offer.find(['time']).get_text()))\n",
    "    \n",
    "    # scrape salary - only possible with login\n",
    "    #salary_list = []\n",
    "    #for job_offer in job_offer_list:\n",
    "        #job_offer.find_all(['div'], attrs={'class': 'res-lgmafx'})[0]\n",
    "        #salary_list.append(job_offer.find(['span'], attrs={'class': 'res-1fad2gj'}).get_text())\n",
    "\n",
    "    # scrape remote \n",
    "    job_remote_list = []\n",
    "    for job_offer in job_offer_list:\n",
    "        result = job_offer.find_all(['div'], attrs={'class': 'res-lgmafx'})\n",
    "        remote = result[0].find(['span'], attrs={'class': 'res-1qh7elo'})\n",
    "        if not remote:\n",
    "            job_remote_list.append('On-site')\n",
    "        else:\n",
    "            remote_text = remote.find(['span'], attrs={'class': 'res-btchsq'}).get_text()\n",
    "            if remote_text == 'Teilweise Home-Office':\n",
    "                job_remote_list.append('Hybrid')\n",
    "            elif remote_text == 'Nur Home-Office':\n",
    "                job_remote_list.append('Remote')\n",
    "            else:\n",
    "                job_remote_list.append('On-site')\n",
    "\n",
    "    df_enrich['job_title'] = job_title_list\n",
    "    df_enrich['company_name'] = company_name_list\n",
    "    df_enrich['post_date'] = post_date_list\n",
    "    #df_enrich[''] = number_of_employees\n",
    "    #df_enrich[''] = num_applicants\n",
    "    df_enrich['job_type'] = job_type_list\n",
    "    #df_enrich[''] = job_level_list\n",
    "    df_enrich['job_remote'] = job_remote_list\n",
    "    df_enrich['language'] = language_list    \n",
    "    #df_enrich[''] = salary_list\n",
    "    df_enrich['sector'] = sector_list\n",
    "    df_enrich['source'] = source_list\n",
    "    df_enrich['search_term'] = search_term_list\n",
    "    \n",
    "    df_combined = pd.concat([df_base, df_enrich],axis=0)\n",
    "    return df_combined\n",
    "\n",
    "def handle_date(stepstone_post_date):\n",
    "    sliced = stepstone_post_date.split(' ', 2)\n",
    "    date_number = int(sliced[1])\n",
    "    time_format = sliced[2]\n",
    "    date = datetime.now()\n",
    "    \n",
    "    match time_format:\n",
    "        case 'Stunden' | 'Stunde':\n",
    "            date = date - timedelta(hours=date_number)\n",
    "        case 'Tagen' | 'Tag':\n",
    "            date = date - timedelta(days=date_number)\n",
    "        case 'Wochen' | 'Woche':\n",
    "            date = date - timedelta(weeks=date_number)\n",
    "        case 'Monate' | 'Monat':\n",
    "            date = date - timedelta(months=date_number)\n",
    "        case _:\n",
    "           date = date\n",
    "    return date.strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a8214e-81a4-4569-893c-b7c6ce3537ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "https://www.stepstone.de/jobs/vollzeit/data-analyst/in-berlin?radius=30&whereType=autosuggest&page=1action=facet_selected%3bworktypes%3b80001&fdl=en&se=21000&wci=419239&sort=1&action=sort_relevance\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# scrape for testing purpose\n",
    "test = enrich_dataset('data-analyst', '1', 'en', 'vollzeit', '21000', df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816d413-8eae-4c88-be96-0150e2626535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
